import random
from datetime import datetime
from models.models_utils import *
from utils import *
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from models.Shallow_ML_models import *
import sklearn.metrics


def setup():
    current_time_str = str(datetime.now().strftime("%d-%b-%Y_%H_%M_%S"))
    LOG_DIR = os.path.join(LOG_MASTER_DIR, current_time_str)
    os.makedirs(LOG_DIR)
    return LOG_DIR


def execute_deep_feedforward_model(model_params, LOG_DIR):
    print(f'Model params: {model_params}')

    batch_size = model_params['batch_size']
    image_dim = model_params['image_dim']
    data_path = get_datapath(image_dim)
    train_loader, val_loader, dataset_len, class_names = get_data_loaders(data_path=data_path,
                                                                          image_dim=image_dim,
                                                                          batch_size=batch_size)

    train_set_len = len(train_loader) * batch_size
    val_set_len = len(val_loader) * batch_size
    num_of_classes = len(class_names)

    model_params['num_of_classes'] = num_of_classes
    model_params['class_names'] = class_names

    # print(f'Training images available: {train_set_len}')
    # print(f'Validation images available: {val_set_len}')
    # print(f'Total images available: {dataset_len}')
    # print(f'Number of classes: {num_of_classes}')

    model = create_deep_feedforward_model(model_params)
    criterion = nn.CrossEntropyLoss()

    model, train_losses, train_accuracy = train_ann_model(model=model, model_params=model_params, criterion=criterion,
                                                          train_loader=train_loader, log_dir=LOG_DIR)
    test_accuracy, predicted, ground_truth = test_ann_model(model=model, model_params=model_params, criterion=criterion,
                                                            val_loader=val_loader)

    print(f'Test accuracy: {test_accuracy:7.4f}%')

    model_params['train_accuracy'] = train_accuracy[-1]
    model_params['test_accuracy'] = test_accuracy
    save_model_results_to_log(model=model, model_params=model_params,
                              train_losses=train_losses, train_accuracy=train_accuracy,
                              predicted=predicted, ground_truth=ground_truth,
                              log_dir=LOG_DIR)


def process_deep_learning(LOG_DIR):
    """
            {
            'experiment_name': 'experiment_1',
            'model_name': 'CNNMalware_Model1',
            'batch_size': 64,
            'image_dim': 1024,
            'epochs': 2,
            'lr': 0.001
        },
        {
            'experiment_name': 'experiment_2',
            'model_name': 'CNNMalware_Model1',
            'batch_size': 64,
            'image_dim': 64,
            'epochs': 1,
            'lr': 0.1
        },
        {
            'experiment_name': 'experiment_3',
            'model_name': 'CNNMalware_Model1',
            'batch_size': 64,
            'image_dim': 64,
            'epochs': 1,
            'lr': 0.01
        },

        {
            'experiment_name': 'experiment_2',
            'model_name': 'ANNMalware_Model1',
            'batch_size': 64,
            'image_dim': 64,
            'epochs': 2,
            'lr': 0.1
        },
        {
            'experiment_name': 'experiment_3',
            'model_name': 'ANNMalware_Model2',
            'batch_size': 64,
            'image_dim': 64,
            'epochs': 5,
            'lr': 0.001
        }
    """
    list_of_model_params = [

        {
            'experiment_name': 'experiment_3',
            'model_name': 'ANNMalware_Model2',
            'batch_size': 2,
            'image_dim': 256,
            'epochs': 5,
            'lr': 0.001
        }
    ]

    fina_results = []
    for ml in list_of_model_params:
        print_line()
        print(f'Executing : {ml["experiment_name"]}')
        print_line()
        execute_deep_feedforward_model(ml, LOG_DIR)
        temp_dict = {'experiment_name': ml['experiment_name'],
                     'train_accuracy': ml['train_accuracy'],
                     'test_accuracy': ml['test_accuracy']}
        fina_results.append(temp_dict)

    save_models_metadata_to_log(fina_results, LOG_DIR)


def prepare_shallow_model(model_params, LOG_DIR):
    print(f'Model params: {model_params}')
    df = pd.read_csv(ORG_DATASET_FEATURES_CSV)

    # sort class names and re-assign the new class IDs w.r.t. sored classes.
    df.sort_values(by=['Malware_ClassName'], inplace=True)
    malware_classes = df['Malware_ClassName'].values
    malware_classes = sorted(list(set(list(malware_classes))))
    new_class_ids = df.apply(lambda row: malware_classes.index(row['Malware_ClassName']), axis=1)
    df['Malware_ClassID'] = new_class_ids

    data = df.drop(['Name', 'md5', 'Malware_ClassName'], axis=1)
    x = data.drop(['Malware_ClassID'], axis=1)
    y = data['Malware_ClassID']
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)

    model_params['num_of_classes'] = len(malware_classes)
    model_params['class_names'] = malware_classes

    sc = StandardScaler()
    x_train = sc.fit_transform(x_train)
    x_test = sc.transform(x_test)

    model, gsc_model = create_shallow_model(model_params=model_params)

    x_pred, y_pred, best_estimator, best_params = execute_shallow_model(model=gsc_model, x_train=x_train,
                                                                        y_train=y_train, x_test=x_test)

    test_accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)
    print(f'Test accuracy: {test_accuracy:7.4f}%')
    model_params['train_accuracy'] = 0
    model_params['test_accuracy'] = test_accuracy

    save_model_results_to_log(model=best_estimator, model_params=model_params,
                              predicted=y_pred, ground_truth=y_test, best_params=best_params,
                              log_dir=LOG_DIR)


def process_shallow_learning(LOG_DIR):
    """
    {
            'experiment_name': 'experiment_3',
            'model_name': 'XGB',
            'param_grid': {
                'max_depth': [5, 15, 20],
                'learning_rate': [0.1, 0.01, 0.001],
                'n_estimators': [4, 5, 10],
            },
        },
        {
            'experiment_name': 'experiment_3',
            'model_name': 'RandomForest',
            'param_grid': {
                'criterion': ['gini', 'entropy'],
                'n_estimators': [10, 40, 100, 500],
            },
        }

    """
    list_of_model_params = [
        {
            'experiment_name': 'experiment_1',
            'model_name': 'Knn',
            'param_grid': {
                'n_neighbors': list(range(1, 100, 2)),
                'p': [1, 2],
            },
        }

    ]

    final_results = []
    for ml in list_of_model_params:
        print_line()
        print(f'Executing : {ml["experiment_name"]}')
        print_line()
        prepare_shallow_model(ml, LOG_DIR)
        temp_dict = {'experiment_name': ml['experiment_name'],
                     'train_accuracy': ml['train_accuracy'],
                     'test_accuracy': ml['test_accuracy']}
        final_results.append(temp_dict)

    save_models_metadata_to_log(final_results, LOG_DIR)


def main(LOG_DIR):
    # process_deep_learning(LOG_DIR)
    process_shallow_learning(LOG_DIR)


def print_banner(LOG_DIR):
    print_line()
    if use_cuda:
        print('Using GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))
    else:
        print('Running on :', device)

    print(f'LOG_DIR = {LOG_DIR}')
    print_line()


if __name__ == '__main__':
    LOG_DIR = setup()
    print_banner(LOG_DIR)
    main(LOG_DIR)
    print_banner(LOG_DIR)
